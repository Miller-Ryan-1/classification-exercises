{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfcca26",
   "metadata": {},
   "source": [
    "### 2. Hand eval given confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "827fb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46, 13],\n",
       "       [ 7, 34]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([[46,13],[7,34]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f586aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7796610169491526, 0.8679245283018868, 0.8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46/(46+13), 46/(46+7), (46+34)/(46+7+13+34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5d79f",
   "metadata": {},
   "source": [
    "Precision = .78 | Recall = .87 | Accuracy = .8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47621914",
   "metadata": {},
   "source": [
    "In the context of this problem, what is a false positive?\n",
    "- We predicted a dog and the actual animal was a cat.\n",
    "\n",
    "In the context of this problem, what is a false negative?\n",
    "- We predicted a cat and the actual animal was a dog.\n",
    "\n",
    "How would you describe this model?\n",
    "- This model predicts whether a picture is a cat or a dog.  We are using the dog as a positive case, in accordance with the standard layout.  As a cat owner, I know it is FAR WORSE for a False Positive to happen, so Precision is most important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ba65b",
   "metadata": {},
   "source": [
    "### 3. Rubber Duckys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab5e97c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_c3 = pd.read_csv('c3.csv')\n",
    "df_c3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe364ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model1</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model1     Defect  No Defect\n",
       "actual                      \n",
       "Defect          8          8\n",
       "No Defect       2        182"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_c3.actual, df_c3.model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b2f1b",
   "metadata": {},
   "source": [
    "TP: 8\n",
    "FP: 2\n",
    "TN: 182\n",
    "FN: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9431a086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model2</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>81</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model2     Defect  No Defect\n",
       "actual                      \n",
       "Defect          9          7\n",
       "No Defect      81        103"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_c3.actual, df_c3.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "271e0a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model3</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model3     Defect  No Defect\n",
       "actual                      \n",
       "Defect         13          3\n",
       "No Defect      86         98"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_c3.actual, df_c3.model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b605712e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FP</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>182</td>\n",
       "      <td>103</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  measure  model1  model2  model3\n",
       "0      TP       8       9      13\n",
       "1      FP       2      81      86\n",
       "2      TN     182     103      98\n",
       "3      FN       8       7       3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3_model_results = pd.DataFrame({'measure':['TP','FP','TN','FN'],\n",
    "                   'model1': [8,2,182,8],\n",
    "                   'model2': [9,81,103,7],\n",
    "                   'model3': [13,86,98,3]})\n",
    "c3_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b65499",
   "metadata": {},
   "source": [
    "An internal team wants to investigate the cause of the manufacturing defects. They tell you that they want to identify as many of the ducks that have a defect as possible. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?\n",
    "- They want to minimize False Negatives, so they are focused on Recall.  As such they would use Model 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2503f",
   "metadata": {},
   "source": [
    "Recently several stories in the local news have come out highlighting customers who received a rubber duck with a defect, and portraying C3 in a bad light. The PR team has decided to launch a program that gives customers with a defective duck a vacation to Hawaii. They need you to predict which ducks will have defects, but tell you the really don't want to accidentally give out a vacation package when the duck really doesn't have a defect. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?\n",
    "- This question is confusing because the duck, when it gets to the customer or not already has the defect, so we would want to identify as many as possible just as in the above question, so Recall + Model 3.  If the vacations are driven by the number of positives in the model, then I would go with Model 1 (Precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18faee",
   "metadata": {},
   "source": [
    "### 4. Cats and Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69fa0234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4\n",
       "0    cat    cat    dog    cat    dog\n",
       "1    dog    dog    cat    cat    dog"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gyp = pd.read_csv('gives_you_paws.csv')\n",
    "df_gyp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a56742",
   "metadata": {},
   "source": [
    "Given this dataset, use pandas to create a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09110688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    3254\n",
       "cat    1746\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gyp.actual.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dfb3bb",
   "metadata": {},
   "source": [
    "Dog is the most common class, so Baseline = all Dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c551a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    5000\n",
       "Name: mymodel, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gyp['mymodel'] = 'dog'\n",
    "#can programmatically use value_counts.idxmax() to assign it to most common animal\n",
    "df_gyp.mymodel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c53a150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>mymodel</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0</td>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0</td>\n",
       "      <td>3254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "mymodel  cat   dog\n",
       "actual            \n",
       "cat        0  1746\n",
       "dog        0  3254"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel = pd.crosstab(df_gyp.actual, df_gyp.mymodel)\n",
    "mymodel['cat'] = 0\n",
    "mymodel = mymodel.reindex(columns =['cat','dog'])\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15ac8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_results(df):\n",
    "    true_positive = df.iloc[1,1]\n",
    "    false_positive = df.iloc[0,1]\n",
    "    true_negative = df.iloc[0,0]\n",
    "    false_negative = df.iloc[1,0]\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "    print(f'True Positive = {true_positive}')\n",
    "    print(f'False Positive = {false_positive}')\n",
    "    print(f'True Negative = {true_negative}')\n",
    "    print(f'False Negative = {false_negative}')\n",
    "    print(f'Precision = {precision}')\n",
    "    print(f'Recall = {recall}')\n",
    "    print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d31d8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model1</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1423</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>640</td>\n",
       "      <td>2614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model1   cat   dog\n",
       "actual            \n",
       "cat     1423   323\n",
       "dog      640  2614"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = pd.crosstab(df_gyp.actual, df_gyp.model1)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a396cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model2</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1555</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1657</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model2   cat   dog\n",
       "actual            \n",
       "cat     1555   191\n",
       "dog     1657  1597"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = pd.crosstab(df_gyp.actual, df_gyp.model2)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "952a4e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model3</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>893</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1599</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model3   cat   dog\n",
       "actual            \n",
       "cat      893   853\n",
       "dog     1599  1655"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = pd.crosstab(df_gyp.actual, df_gyp.model3)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0cad000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model4</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>603</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>144</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model4  cat   dog\n",
       "actual           \n",
       "cat     603  1143\n",
       "dog     144  3110"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = pd.crosstab(df_gyp.actual, df_gyp.model4)\n",
    "model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfc1302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive = 3254\n",
      "False Positive = 1746\n",
      "True Negative = 0\n",
      "False Negative = 0\n",
      "Precision = 0.6508\n",
      "Recall = 1.0\n",
      "Accuracy = 0.6508\n",
      "None\n",
      "\n",
      "-----------------\n",
      "\n",
      "True Positive = 2614\n",
      "False Positive = 323\n",
      "True Negative = 1423\n",
      "False Negative = 640\n",
      "Precision = 0.8900238338440586\n",
      "Recall = 0.803318992009834\n",
      "Accuracy = 0.8074\n",
      "None\n",
      "\n",
      "-----------------\n",
      "\n",
      "True Positive = 1597\n",
      "False Positive = 191\n",
      "True Negative = 1555\n",
      "False Negative = 1657\n",
      "Precision = 0.8931767337807607\n",
      "Recall = 0.49078057775046097\n",
      "Accuracy = 0.6304\n",
      "None\n",
      "\n",
      "-----------------\n",
      "\n",
      "True Positive = 1655\n",
      "False Positive = 853\n",
      "True Negative = 893\n",
      "False Negative = 1599\n",
      "Precision = 0.6598883572567783\n",
      "Recall = 0.5086047940995697\n",
      "Accuracy = 0.5096\n",
      "None\n",
      "\n",
      "-----------------\n",
      "\n",
      "True Positive = 3110\n",
      "False Positive = 1143\n",
      "True Negative = 603\n",
      "False Negative = 144\n",
      "Precision = 0.7312485304490948\n",
      "Recall = 0.9557467732022127\n",
      "Accuracy = 0.7426\n",
      "None\n",
      "\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [mymodel,model1,model2,model3,model4]\n",
    "for model in models:\n",
    "    print(matrix_results(model))\n",
    "    print('\\n-----------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d84da9",
   "metadata": {},
   "source": [
    "In terms of accuracy, how do the various models compare to the baseline model? Are any of the models better than the baseline?\n",
    "- Models 1 and 4 are better (Model 4 is the best)\n",
    "\n",
    "Suppose you are working on a team that solely deals with dog pictures. Which of these models would you recomend for Phase I? For Phase II?\n",
    "- For Phase I we want to minimize False Negatives (Recall) such that we don't miss lots of dogs.  As such, the Baseline and Model 4 are superior.  For Phase II, we optimaize for Flase Positives (Precision).\n",
    "\n",
    "Suppose you are working on a team that solely deals with cat pictures. Which of these models would you recomend for Phase I? For Phase II?\n",
    "- Will wait for the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1019b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "add829fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6508\n",
      "0.8074\n",
      "0.6304\n",
      "0.5096\n",
      "0.7426\n"
     ]
    }
   ],
   "source": [
    "new_models = [df_gyp.mymodel,df_gyp.model1,df_gyp.model2,df_gyp.model3,df_gyp.model4]\n",
    "\n",
    "for i in range(5):\n",
    "    print(skm.accuracy_score(df_gyp.actual, new_models[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7aa75a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.358347</td>\n",
       "      <td>0.659888</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.509118</td>\n",
       "      <td>0.554590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.511455</td>\n",
       "      <td>0.508605</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.510030</td>\n",
       "      <td>0.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.421425</td>\n",
       "      <td>0.574453</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.497939</td>\n",
       "      <td>0.521016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1746.000000</td>\n",
       "      <td>3254.000000</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   cat          dog  accuracy    macro avg  weighted avg\n",
       "precision     0.358347     0.659888    0.5096     0.509118      0.554590\n",
       "recall        0.511455     0.508605    0.5096     0.510030      0.509600\n",
       "f1-score      0.421425     0.574453    0.5096     0.497939      0.521016\n",
       "support    1746.000000  3254.000000    0.5096  5000.000000   5000.000000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in range(5):\n",
    "pd.DataFrame(skm.classification_report(df_gyp.actual, new_models[3], labels = ['cat','dog'], output_dict = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
