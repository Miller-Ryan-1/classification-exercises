{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c0107b",
   "metadata": {},
   "source": [
    "# I. Acquire Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cc64d",
   "metadata": {},
   "source": [
    "## 1-3. Completed\n",
    "## 4. In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ba81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad136b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8991fad",
   "metadata": {},
   "source": [
    "Print the first three rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611cbce",
   "metadata": {},
   "source": [
    "Print the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e569ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27f06f",
   "metadata": {},
   "source": [
    "Print the column names and data types of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e38879",
   "metadata": {},
   "source": [
    "### * Next two are the preferred methods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcda4c",
   "metadata": {},
   "source": [
    "Print the summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ba28a",
   "metadata": {},
   "source": [
    "## 5. Read the Table1_CustDetails table from your spreadsheet exercises google sheet into a dataframe named df_google_sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1jvEKrZGWuNGA8b7aZT-e28TceYP-nw18mjReCT03RWo/edit#gid=1756832831'\n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_google_sheets = pd.read_csv(csv_export_url)\n",
    "df_google_sheets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a9682",
   "metadata": {},
   "source": [
    "Assign the first 100 rows to a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b34b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets_sample = df_google_sheets.head(100)\n",
    "df_google_sheets_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d15881",
   "metadata": {},
   "source": [
    "Print the number of rows of your original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02742866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6639e",
   "metadata": {},
   "source": [
    "Print the first 5 column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets_sample.columns[:5].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6ed97",
   "metadata": {},
   "source": [
    "Print the column names that have a data type of object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets_sample.select_dtypes(include = 'object').columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558aa79",
   "metadata": {},
   "source": [
    "Compute the range for each of the numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets_sample.describe().max() - df_google_sheets_sample.describe().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_sheets.describe().T['max'] - df_google_sheets.describe().T['min']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0b755",
   "metadata": {},
   "source": [
    "## 6.  Download your spreadsheet exercises google sheet as an excel file (File → Download → Microsoft Excel). Read the Table1_CustDetails worksheet into a dataframe named df_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('Storytelling Project Data.xlsx', sheet_name='Table1_CustDetails')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9c775",
   "metadata": {},
   "source": [
    "Assign the first 100 rows to a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample = df_excel.head(100)\n",
    "df_excel_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac29bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample.select_dtypes(include = 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a909981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample.describe().max() - df_excel_sample.describe().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b8887",
   "metadata": {},
   "source": [
    "## 7.  Read the data from this google sheet into a dataframe, df_google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'\n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_google = pd.read_csv(csv_export_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e638ce",
   "metadata": {},
   "source": [
    "Print the first 3 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925269e",
   "metadata": {},
   "source": [
    "Print the number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528196b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee40313",
   "metadata": {},
   "source": [
    "Print the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fbb0e",
   "metadata": {},
   "source": [
    "Print the data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578c95b",
   "metadata": {},
   "source": [
    "Print summary stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702438df",
   "metadata": {},
   "source": [
    "**** Print unique values for each categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef71d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google[['Sex','Cabin','Embarked']].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f0d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanicz = acquire.get_titanic_data()\n",
    "titanicz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab613e72",
   "metadata": {},
   "source": [
    "# II. Prepare Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba23cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745675c5",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed09b4",
   "metadata": {},
   "source": [
    "1. Use the function defined in acquire.py to load the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_iris_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e75332",
   "metadata": {},
   "source": [
    "2.  Drop the species_id and measurement_id columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d87606",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['species_id','measurement_id']\n",
    "df_iris = df_iris.drop(columns = columns_to_drop)\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843cfaa",
   "metadata": {},
   "source": [
    "3. Rename the species_name column to just species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = df_iris.rename(columns={'species_name': 'species'})\n",
    "df_iris = df_iris.drop_duplicates()\n",
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed893491",
   "metadata": {},
   "source": [
    "4. Create dummy variables of the species name and concatenate onto the iris dataframe. (This is for practice, we don't always have to encode the target, but if we used species as a feature, we would need to encode it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df_iris = pd.get_dummies(df_iris[['species']], drop_first = True)\n",
    "data = pd.concat([df_iris, dummy_df_iris], axis=1)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb824d",
   "metadata": {},
   "source": [
    "5. Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_iris(df):\n",
    "    df = df.drop_duplicates()\n",
    "    columns_to_drop = ['species_id','measurement_id']\n",
    "    df = df.drop(columns = columns_to_drop)\n",
    "    df = df.rename(columns={'species_name': 'species'})\n",
    "    dummy_df = pd.get_dummies(df[['species']], drop_first = True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_iris(df_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b695172",
   "metadata": {},
   "source": [
    "### Titanics Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732020df",
   "metadata": {},
   "source": [
    "1. Use the function defined in acquire.py to load the Titanic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c94555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass   sex   age  sibsp  parch     fare  \\\n",
       "449           449         1       1  male  52.0      0      0  30.5000   \n",
       "462           462         0       1  male  47.0      0      0  38.5000   \n",
       "512           512         1       1  male  36.0      0      0  26.2875   \n",
       "821           821         1       3  male  27.0      0      0   8.6625   \n",
       "589           589         0       3  male   NaN      0      0   8.0500   \n",
       "\n",
       "    embarked  class deck  embark_town  alone  \n",
       "449        S  First    C  Southampton      1  \n",
       "462        S  First    E  Southampton      1  \n",
       "512        S  First    E  Southampton      1  \n",
       "821        S  Third  NaN  Southampton      1  \n",
       "589        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = acquire.get_titanic_data()\n",
    "df_titanic.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ae69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926eacc9",
   "metadata": {},
   "source": [
    "2. Drop any unnecessary, unhelpful, or duplicated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c91fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>Siblings/Spouses</th>\n",
       "      <th>Parents/Children</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  Siblings/Spouses  Parents/Children  \\\n",
       "0           0       3    male  22.0                 1                 0   \n",
       "1           1       1  female  38.0                 1                 0   \n",
       "2           1       3  female  26.0                 0                 0   \n",
       "3           1       1  female  35.0                 1                 0   \n",
       "4           0       3    male  35.0                 0                 0   \n",
       "..        ...     ...     ...   ...               ...               ...   \n",
       "886         0       2    male  27.0                 0                 0   \n",
       "887         1       1  female  19.0                 0                 0   \n",
       "888         0       3  female   NaN                 1                 2   \n",
       "889         1       1    male  26.0                 0                 0   \n",
       "890         0       3    male  32.0                 0                 0   \n",
       "\n",
       "        fare  embark_town  alone  \n",
       "0     7.2500  Southampton      0  \n",
       "1    71.2833    Cherbourg      0  \n",
       "2     7.9250  Southampton      1  \n",
       "3    53.1000  Southampton      0  \n",
       "4     8.0500  Southampton      1  \n",
       "..       ...          ...    ...  \n",
       "886  13.0000  Southampton      1  \n",
       "887  30.0000  Southampton      1  \n",
       "888  23.4500  Southampton      0  \n",
       "889  30.0000    Cherbourg      1  \n",
       "890   7.7500   Queenstown      1  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = df_titanic.drop_duplicates()\n",
    "columns_to_drop = ['passenger_id','deck','class','embarked']\n",
    "df_titanic = df_titanic.drop(columns = columns_to_drop).rename(columns={'sibsp': 'Siblings/Spouses','parch':'Parents/Children'})\n",
    "df_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c89daf",
   "metadata": {},
   "source": [
    "3. Encode the categorical columns. Create dummy variables of the categorical columns and concatenate them onto the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d5f5869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>Siblings/Spouses</th>\n",
       "      <th>Parents/Children</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  Siblings/Spouses  Parents/Children  \\\n",
       "0           0       3    male  22.0                 1                 0   \n",
       "1           1       1  female  38.0                 1                 0   \n",
       "2           1       3  female  26.0                 0                 0   \n",
       "3           1       1  female  35.0                 1                 0   \n",
       "4           0       3    male  35.0                 0                 0   \n",
       "..        ...     ...     ...   ...               ...               ...   \n",
       "886         0       2    male  27.0                 0                 0   \n",
       "887         1       1  female  19.0                 0                 0   \n",
       "888         0       3  female   NaN                 1                 2   \n",
       "889         1       1    male  26.0                 0                 0   \n",
       "890         0       3    male  32.0                 0                 0   \n",
       "\n",
       "        fare  embark_town  alone  sex_male  embark_town_Queenstown  \\\n",
       "0     7.2500  Southampton      0         1                       0   \n",
       "1    71.2833    Cherbourg      0         0                       0   \n",
       "2     7.9250  Southampton      1         0                       0   \n",
       "3    53.1000  Southampton      0         0                       0   \n",
       "4     8.0500  Southampton      1         1                       0   \n",
       "..       ...          ...    ...       ...                     ...   \n",
       "886  13.0000  Southampton      1         1                       0   \n",
       "887  30.0000  Southampton      1         0                       0   \n",
       "888  23.4500  Southampton      0         0                       0   \n",
       "889  30.0000    Cherbourg      1         1                       0   \n",
       "890   7.7500   Queenstown      1         1                       1   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  \n",
       "..                       ...  \n",
       "886                        1  \n",
       "887                        1  \n",
       "888                        1  \n",
       "889                        0  \n",
       "890                        0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df_titanic = pd.get_dummies(df_titanic[['sex', 'embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "df_titanic = pd.concat([df_titanic, dummy_df_titanic], axis = 1)\n",
    "df_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf0ca6",
   "metadata": {},
   "source": [
    "4. Create a function named prep_titanic that accepts the raw titanic data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ff0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic(df):\n",
    "    df = df.drop_duplicates()\n",
    "    columns_to_drop = ['passenger_id','deck','class','embarked']\n",
    "    df = df.drop(columns = columns_to_drop).rename(columns={'sibsp': 'Siblings/Spouses','parch':'Parents/Children'})\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c87b0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['passenger_id' 'deck' 'class' 'embarked'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nw/8yyyyp8n70vbplhdsylyqs8c0000gn/T/ipykernel_86422/197460317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprep_titanic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_titanic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/nw/8yyyyp8n70vbplhdsylyqs8c0000gn/T/ipykernel_86422/420272300.py\u001b[0m in \u001b[0;36mprep_titanic\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcolumns_to_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'passenger_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deck'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'embarked'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns_to_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sibsp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Siblings/Spouses'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'parch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Parents/Children'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdummy_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embark_town'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4905\u001b[0m         \"\"\"\n\u001b[0;32m-> 4906\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['passenger_id' 'deck' 'class' 'embarked'] not found in axis\""
     ]
    }
   ],
   "source": [
    "prep_titanic(df_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff222576",
   "metadata": {},
   "source": [
    "### Telco Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco = acquire.get_telco_data()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_telco.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300da760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_telco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco(df):\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    df['total_charges'] = df['total_charges'].str.strip()\n",
    "    df = df[df.total_charges != '']\n",
    "    \n",
    "    # Convert to correct datatype\n",
    "    df['total_charges'] = df.total_charges.astype(float)\n",
    "    \n",
    "    df['gender_encoded'] = df.gender.map({'Female': 1, 'Male': 0})\n",
    "    df['partner_encoded'] = df.partner.map({'Yes': 1, 'No': 0})\n",
    "    df['dependents_encoded'] = df.dependents.map({'Yes': 1, 'No': 0})\n",
    "    df['phone_service_encoded'] = df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    df['paperless_billing_encoded'] = df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "    df['churn_encoded'] = df.churn.map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    columns_to_drop = ['monthly_charges.1','customer_id', 'total_charges.1','paperless_billing.1','payment_type_id.1','internet_service_type_id','contract_type_id','payment_type_id']\n",
    "    df = df.drop(columns = columns_to_drop).rename(columns={'sibsp': 'Siblings/Spouses','parch':'Parents/Children'})\n",
    "    \n",
    "    dummy_df = pd.get_dummies(df[['multiple_lines', \\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type']], dummy_na=False, \\\n",
    "                              drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_train, telco_validate, telco_test = prepare.prep_telco(df_telco)\n",
    "telco_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e900d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_train.shape, telco_validate.shape, telco_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023d289",
   "metadata": {},
   "source": [
    "# III. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabc3c3",
   "metadata": {},
   "source": [
    "## *See \"EDA Work\" Jupyter Notebook found in this repo for work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
